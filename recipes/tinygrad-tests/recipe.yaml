context:
  version: "0.10.2"
  build_number: 0
  # see github.com/conda-forge/conda-forge.github.io/issues/1059 for naming discussion
  proc_type: ${{ "cuda" ~ cuda_compiler_version | version_to_buildstring if cuda_compiler_version != "None" else "cpu" }}
  tests_to_skip: >
    _not_a_real_test
    ${{ "fails `assert Device.DEFAULT in failed_platforms`" if 0 }}
    ${{ " or (TestLinearizerFailures and test_failure_27)" if linux }}
    ${{ "Causes `Fatal Python error: Bus error` + segfault" if 0 }}
    ${{ " or testCopySHMtoDefault" if linux }}
    ${{ "`RuntimeError: Attempting to relocate against an undefined symbol 'fmaxf'" if 0 }}
    ${{ " or test_backward_sum_acc_dtype" if linux }}
    ${{ "RuntimeError: Attribute list does not match Module context!" if 0 }}
    ${{ " or test_bf16_disk_write_read" if linux and cuda_compiler_version != "None" }}
    ${{ "`error: use of undefined value '@.const.pickledata.7893608704'`" if 0 }}
    ${{ " or (TestWhisper and (test_transcribe_batch21 or test_transcribe_file1))" if osx }}
    ${{ "signed int32 overflow" if 0 }}
    ${{ " or test_float_midcast_int32" if osx }}
    ${{ "tinygrad.codegen.kernel.KernelOptError: must have tensor cores or TC=2" if 0 }}
    ${{ " or test_unmerged_ifs" if osx }}

recipe:
  name: tinygrad
  version: ${{ version }}

source:
  url: https://github.com/tinygrad/tinygrad/archive/refs/tags/v${{ version }}.tar.gz
  sha256: 3e0fd20a2df28e95ee2c6c5aa02a1cf872ea8ff285ea74ee91d76c694c03b3ae
  patches:
    - patches/0001-rely-on-the-packaged-CUDA-toolchain.patch

build:
  number: ${{ build_number }}
  string: ${{ proc_type }}_py${{ python | version_to_buildstring }}_h${{ hash }}_${{ build_number }}
  skip:
    - match(python, "<3.10")
    # toolchain for 11.8 is not usable in end-user environment
    - match(cuda_compiler_version, "==11.8")

outputs:
  - package:
      name: tinygrad
    build:
      script: python -m pip install . -vv
    requirements:
      build:
        - if: build_platform != target_platform
          then:
            - python
            - cross-python_${{ target_platform }}
        # this is just here so smithy creates separate jobs for the CUDA variants
        - if: cuda_compiler_version != "None"
          then:
            - ${{ stdlib("c") }}
            - ${{ compiler("cxx") }}
            - ${{ compiler("cuda") }}
      host:
        - python
        - pip
        - setuptools
      run:
        - python
        - if: win
          then:
            - clang-cl_${{ target_platform }}
          else:
            - clangxx_${{ target_platform }}
        - if: cuda_compiler_version != "None"
          then:
            - cuda-nvcc_${{ target_platform }}
        - if: cuda_compiler_version != "None" and linux
          then:
            - triton
    tests:
      - python:
          imports:
            - tinygrad
          pip_check: true

  - package:
      name: tinygrad-tests
    build:
      # silly: https://github.com/prefix-dev/rattler-build/pull/1367
      script: ${{ 'true' if unix else 'exit /b 0' }}
    requirements:
      run:
        - ${{ pin_subpackage('tinygrad', exact=True) }}
    tests:
      - requirements:
          run:
            # minimal
            - pytest
            - pytest-xdist
            - hypothesis
            - numpy
            - pytorch
            # optional
            - blobfile
            - bottle
            - if: x86_64
              then:
                - capstone
            # https://github.com/conda-forge/staged-recipes/issues/29179
            # - ggml-python
            - if: unix
              then:
                # not available on windows yet
                - jax
            - librosa
            - networkx
            - nibabel
            - onnx2torch
            - onnx
            - py-opencv
            - pillow
            - safetensors
            - sentencepiece
            - tabulate
            - tiktoken
            - tqdm
            - transformers
        files:
          source:
            - examples/
            - extra/
            - test/
        script:
          # test suite in emulation on aarch is super slow
          - if: unix and build_platform == target_platform
            then:
              - pytest -n 2 -v test/ -k "not (${{ tests_to_skip }})"
          - if: win
            then:
              # windows cannot run tests yet due to lack of jax
              - python examples/beautiful_mnist.py
          - echo "just something so aarch doesn't have an empty script section"

about:
  homepage: https://github.com/tinygrad/tinygrad
  summary: 'You like pytorch? You like micrograd? You love tinygrad! ❤️'
  description: |
    This may not be the best deep learning framework, but it is a deep learning framework.

    Due to its extreme simplicity, it aims to be the easiest framework to add new accelerators to,
    with support for both inference and training. If XLA is CISC, tinygrad is RISC.
  license: MIT
  license_file: LICENSE
  documentation: https://docs.tinygrad.org/
  repository: https://github.com/tinygrad/tinygrad

extra:
  recipe-maintainers:
    - h-vetinari
  feedstock-name: tinygrad
